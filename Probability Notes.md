# Probability Notes

#### Conditional probability

P(A|B) = P(AB) / P(B)

#### Independent events

P(AB) = P(A)* P(B)


#### Binomial distribution 
![image](https://user-images.githubusercontent.com/76275089/126997510-55c19c86-02a2-402f-9c8e-26b5a9e9ec78.png)
![image](https://user-images.githubusercontent.com/76275089/126998892-aab62834-2b3c-42ba-92ae-2882d43985a9.png)


#### Possion distribution

Binomial distribution when p is nearly 0, n closes to infinite
![image](https://user-images.githubusercontent.com/76275089/127008287-01ab230b-589e-4add-af2e-2eaa0e6803c0.png)


#### Joint distribution

P(x, y) = P(X = x, Y = y)


#### Expectation

![image](https://user-images.githubusercontent.com/76275089/127007620-90ba7d1c-a7d6-4ec1-a75f-751472f4cceb.png)

Addition rule: E(X+Y) = E(X) + E(Y)

Indicator: E(I) = P(A), E(X) = P(A1) + P(A2) + ...

Tail sum formula

![image](https://user-images.githubusercontent.com/76275089/127009830-f8db9c88-f0eb-44ef-b4f5-0df95597198b.png)

Markov's inequality

If X > 0, then P(X >= a) <= E(X)/a for every a > 0

![image](https://user-images.githubusercontent.com/76275089/127011327-bba6de29-3073-4fd6-9899-7d66cf623e4a.png)

E(aX+b) = aE(X) + b
















